{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bd402ad",
   "metadata": {},
   "source": [
    "# Machine Learning Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf349bb6",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Bussines understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4be4a3",
   "metadata": {},
   "source": [
    "ğŸ’¡ Pemahaman Business Understanding\n",
    "<br>\n",
    "\n",
    "Sebagai fondasi analisis data yang sukses, Business Understanding adalah langkah kritis yang melibatkan:\n",
    "\n",
    "âœ… Proses Menghasilkan Data\n",
    "\n",
    "Memahami dari mana data berasal, bagaimana data dikumpulkan, dan siapa yang bertanggung jawab atasnya.\n",
    "\n",
    "Ini penting untuk menilai kualitas dan keterbatasan data yang ada.\n",
    "\n",
    "<br>\n",
    "\n",
    "âœ… User Journey\n",
    "\n",
    "Menganalisis alur pengalaman pengguna dari awal hingga akhir.\n",
    "\n",
    "Membantu mengidentifikasi titik-titik kritis (pain points) di mana intervensi data dapat memberikan nilai.\n",
    "\n",
    "<br>\n",
    "\n",
    "âœ… Business Process\n",
    "\n",
    "Memahami alur kerja dan operasional perusahaan secara menyeluruh.\n",
    "\n",
    "Dengan ini, kita bisa:\n",
    "\n",
    "Mengidentifikasi masalah bisnis nyata yang dapat diselesaikan dengan Machine Learning.\n",
    "\n",
    "Menentukan solusi yang paling sesuai dan berdampak."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b70085",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. objective matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a487e76",
   "metadata": {},
   "source": [
    "Dalam pembelajaran mesin, metrik evaluasi adalah alat untuk mengukur seberapa baik kinerja model kita. Anggaplah ini seperti rapor atau hasil tes untuk model Anda. Metrik ini membantu kita memahami kekuatan dan kelemahan model, sama seperti rapor yang menunjukkan apakah Anda lebih baik dalam matematika atau bahasa.\n",
    "\n",
    "1. Matriks Kebingungan (Confusion Matrix)\n",
    "Matriks kebingungan adalah fondasi dari banyak metrik evaluasi. Ini adalah tabel yang merangkum hasil prediksi model. Matriks ini membantu kita melihat prediksi apa yang benar dan prediksi apa yang salah.\n",
    "\n",
    "Ada empat hasil utama yang bisa kita dapatkan:\n",
    "\n",
    "True Positive (TP): Model memprediksi \"positif\" dengan benar.\n",
    "\n",
    "Contoh: Model memprediksi orang ini sakit, dan dia memang sakit.\n",
    "\n",
    "True Negative (TN): Model memprediksi \"negatif\" dengan benar.\n",
    "\n",
    "Contoh: Model memprediksi orang ini tidak sakit, dan dia memang sehat.\n",
    "\n",
    "False Positive (FP): Model memprediksi \"positif,\" tapi salah.\n",
    "\n",
    "Contoh: Model memprediksi orang ini sakit, padahal dia sehat. Ini adalah kesalahan.\n",
    "\n",
    "False Negative (FN): Model memprediksi \"negatif,\" tapi salah.\n",
    "\n",
    "Contoh: Model memprediksi orang ini sehat, padahal dia sakit. Ini adalah kesalahan yang seringkali berbahaya.\n",
    "\n",
    "2. Akurasi (Accuracy)\n",
    "Akurasi adalah metrik paling sederhana yang mengukur seberapa sering model Anda membuat prediksi yang benar secara keseluruhan.\n",
    "\n",
    "Rumus: (TP+TN)/(TP+TN+FP+FN)\n",
    "\n",
    "Kapan digunakan? Ketika jumlah data untuk setiap kategori seimbang.\n",
    "\n",
    "Kelemahan: Akurasi bisa menipu pada data yang tidak seimbang. Misalnya, jika 99% data adalah \"sehat,\" model yang selalu memprediksi \"sehat\" akan memiliki akurasi 99%, tetapi model tersebut tidak berguna.\n",
    "\n",
    "3. Presisi (Precision)\n",
    "Presisi berfokus pada prediksi \"positif\" yang dibuat oleh model. Metrik ini menjawab pertanyaan, \"Dari semua yang model prediksi sebagai 'positif', seberapa banyak yang benar-benar positif?\"\n",
    "\n",
    "Rumus: TP/(TP+FP)\n",
    "\n",
    "Kapan penting? Ketika biaya dari False Positive (kesalahan memprediksi \"positif\") sangat tinggi.\n",
    "\n",
    "Contoh: Filter spam. Kita ingin presisi tinggi agar email penting (bukan spam) tidak masuk ke folder spam.\n",
    "\n",
    "4. Rekal (Recall)\n",
    "Rekal berfokus pada semua kasus \"positif\" yang sebenarnya ada. Metrik ini menjawab pertanyaan, \"Dari semua kasus yang seharusnya 'positif', seberapa banyak yang berhasil ditemukan oleh model?\"\n",
    "\n",
    "Rumus: TP/(TP+FN)\n",
    "\n",
    "Kapan penting? Ketika biaya dari False Negative (kesalahan memprediksi \"negatif\") sangat tinggi.\n",
    "\n",
    "Contoh: Deteksi penyakit. Kita ingin rekal tinggi agar tidak ada pasien yang sakit terlewatkan dan dianggap sehat.\n",
    "\n",
    "5. Skor F1 (F1-Score)\n",
    "Skor F1 adalah metrik yang menggabungkan Presisi dan Rekal menjadi satu nilai. F1-Score sangat berguna saat Anda ingin model yang memiliki keseimbangan baik antara kedua metrik ini, terutama pada dataset yang tidak seimbang.\n",
    "\n",
    "Rumus: 2âˆ—(Presisiâˆ—Rekal)/(Presisi+Rekal)\n",
    "\n",
    "6. Kurva AUC-ROC\n",
    "Kurva AUC-ROC (Area Under the Curve - Receiver Operating Characteristic) adalah grafik yang menunjukkan kemampuan model untuk membedakan antara dua kelas. Semakin tinggi kurvanya, semakin baik modelnya.\n",
    "\n",
    "Skor AUC: Nilai numerik tunggal dari 0 hingga 1.\n",
    "\n",
    "AUC = 1.0: Model sempurna.\n",
    "\n",
    "AUC = 0.5: Modelnya sama dengan menebak secara acak.\n",
    "\n",
    "Keunggulan: Tidak terpengaruh oleh ketidakseimbangan data, sehingga sangat andal untuk membandingkan model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fdaf18",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137669bc",
   "metadata": {},
   "source": [
    "1. Pengumpulan Data (Data Gathering)\n",
    "Langkah pertama adalah mendapatkan data dari sumber yang berbeda-beda. Data mentah ini bisa berasal dari:\n",
    "\n",
    "Database (SQL, NoSQL).\n",
    "\n",
    "File statis (CSV, JSON, Excel, PDF).\n",
    "\n",
    "API (Application Programming Interface).\n",
    "\n",
    "Web scraping.\n",
    "\n",
    "2. Definisi Data (Data Definition)\n",
    "Setelah data terkumpul, kita perlu memahami strukturnya. Tahap ini adalah tentang \"mengenal\" data Anda.\n",
    "\n",
    "Pengecekan Struktur: Lihat jumlah baris dan kolom. Periksa tipe data untuk setiap kolom (dtype).\n",
    "\n",
    "Analisis Statistik Deskriptif: Hitung nilai statistik dasar seperti rata-rata, median, modus, dan standar deviasi.\n",
    "\n",
    "Identifikasi Masalah: Cari tahu apakah ada nilai yang hilang, pencilan (outliers), atau data duplikat.\n",
    "\n",
    "Visualisasi: Gunakan plot sederhana seperti histogram atau boxplot untuk melihat distribusi dan anomali data.\n",
    "\n",
    "3. Validasi Data (Data Validation)\n",
    "Validasi data adalah proses memeriksa keakuratan dan kualitas data berdasarkan aturan atau kriteria yang telah ditentukan.\n",
    "\n",
    "Pengecekan Integritas: Pastikan data berada dalam rentang atau format yang benar.\n",
    "\n",
    "Contoh: Kolom usia tidak boleh memiliki nilai negatif.\n",
    "\n",
    "Konsistensi: Periksa apakah data konsisten di seluruh dataset.\n",
    "\n",
    "Contoh: Nama negara di satu kolom harus sama persis dengan nama di kolom lain.\n",
    "\n",
    "Kualitas Data: Tentukan apakah data cukup berkualitas untuk digunakan. Data yang buruk dapat menyebabkan model yang buruk.\n",
    "\n",
    "4. Pertahanan Data (Data Defense)\n",
    "Ini adalah langkah-langkah untuk menangani masalah yang ditemukan selama validasi, sehingga model dapat berjalan dengan baik.\n",
    "\n",
    "Menangani Nilai Hilang:\n",
    "\n",
    "Imputasi: Mengisi nilai yang hilang dengan nilai yang masuk akal, seperti rata-rata, median, atau modus.\n",
    "\n",
    "Penghapusan: Menghapus baris atau kolom yang memiliki terlalu banyak nilai hilang.\n",
    "\n",
    "Menangani Pencilan (Outliers):\n",
    "\n",
    "Penghapusan: Menghapus data yang ekstrem jika dianggap sebagai kesalahan input.\n",
    "\n",
    "Transformasi: Mengubah nilai pencilan (misalnya, dengan log transformation) agar tidak terlalu mempengaruhi model.\n",
    "\n",
    "Menangani Data Duplikat:\n",
    "\n",
    "Hapus data duplikat untuk mencegah bias pada model.\n",
    "\n",
    "Encoding Variabel Kategorikal:\n",
    "\n",
    "Mengubah data teks menjadi format numerik yang dapat dipahami oleh model.\n",
    "\n",
    "Contoh: Menggunakan One-Hot Encoding untuk mengubah kategori menjadi kolom biner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd4f5a5",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e963000",
   "metadata": {},
   "source": [
    "# 4. Data Spitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc58d16",
   "metadata": {},
   "source": [
    "Tiga Bagian Utama dalam Data Splitting\n",
    "Secara umum, dataset dibagi menjadi tiga bagian:\n",
    "\n",
    "1. Data Pelatihan (Training Data) ğŸ‹ï¸â€â™‚ï¸\n",
    "Ini adalah bagian terbesar dari dataset (biasanya 70-80%). Data ini digunakan untuk melatih model. Model akan belajar pola, fitur, dan hubungan dari data ini untuk membuat prediksi.\n",
    "\n",
    "2. Data Validasi (Validation Data) ğŸ“\n",
    "Bagian ini digunakan untuk menyempurnakan model dan melakukan tuning hyperparameter. Contohnya, Anda mungkin menguji beberapa versi model dengan parameter yang berbeda pada data validasi untuk melihat versi mana yang berkinerja terbaik. Data ini membantu mencegah overfitting pada data pelatihan dan membantu Anda memilih model yang paling optimal sebelum diuji pada data pengujian.\n",
    "\n",
    "3. Data Pengujian (Testing Data) âœ…\n",
    "Bagian ini digunakan untuk mengevaluasi performa akhir dari model Anda. Data pengujian harus tetap \"tersembunyi\" dari model hingga semua proses pelatihan dan tuning selesai. Pengujian pada data ini memberikan gambaran yang paling jujur dan tidak bias tentang seberapa baik model Anda akan bekerja di dunia nyata.\n",
    "\n",
    "Perbandingan dan Ukuran Umum\n",
    "Ukuran pembagian data yang umum adalah:\n",
    "\n",
    "70% Data Pelatihan, 15% Data Validasi, dan 15% Data Pengujian.\n",
    "\n",
    "Atau 80% Data Pelatihan dan 20% Data Pengujian (jika data validasi tidak digunakan secara eksplisit).\n",
    "\n",
    "Pembagian ini penting untuk memastikan model yang kita buat tidak hanya \"menghafal\" data pelatihan, tetapi benar-benar \"belajar\" dan mampu menggeneralisasi pengetahuan untuk memecahkan masalah baru."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0a4d46",
   "metadata": {},
   "source": [
    "# Data Leakage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae2d1e4",
   "metadata": {},
   "source": [
    "Data leakage adalah masalah serius dalam machine learning di mana informasi dari data pengujian (testing data) secara tidak sengaja \"bocor\" ke dalam data pelatihan (training data). Hal ini menyebabkan model memiliki kinerja yang terlihat luar biasa saat pengujian, tetapi sebenarnya gagal total saat diimplementasikan di dunia nyata.\n",
    "\n",
    "Jenis-Jenis Data Leakage\n",
    "Ada dua jenis utama data leakage:\n",
    "\n",
    "1. Kebocoran Data Target (Target Leakage) ğŸ¯\n",
    "Ini terjadi ketika data yang digunakan untuk melatih model menyertakan informasi yang tidak akan tersedia pada saat model membuat prediksi di dunia nyata.\n",
    "\n",
    "Contoh: Anda ingin memprediksi apakah seorang nasabah akan default pinjaman. Jika Anda memasukkan kolom \"pembayaran setelah 3 bulan\" ke dalam data pelatihan, ini akan menyebabkan kebocoran. Mengapa? Karena saat memprediksi nasabah baru, Anda belum memiliki informasi tersebut. Model akan \"mencontek\" dari data target, membuat akurasi terlihat sempurna.\n",
    "\n",
    "2. Kebocoran Data di Tahap Pemrosesan (Data Processing Leakage) ğŸ› ï¸\n",
    "Ini terjadi saat Anda memproses seluruh dataset (termasuk data pengujian) secara bersamaan sebelum membaginya.\n",
    "\n",
    "Contoh: Jika Anda menghitung rata-rata untuk mengisi nilai yang hilang atau menstandarisasi fitur menggunakan seluruh dataset, informasi dari data pengujian telah \"bocor\" ke dalam data pelatihan. Data pengujian seharusnya tetap terisolasi.\n",
    "\n",
    "Cara Mengatasi Data Leakage\n",
    "Mencegah data leakage sangat penting untuk membangun model yang andal. Berikut adalah cara-cara mengatasinya:\n",
    "\n",
    "Lakukan Pembagian Data Terlebih Dahulu: Selalu bagi data Anda menjadi data pelatihan dan pengujian sebelum melakukan pra-pemrosesan. Ini adalah aturan emas.\n",
    "\n",
    "Terapkan Transformasi Secara Terpisah:\n",
    "\n",
    "Hitung parameter transformasi (seperti rata-rata, standar deviasi) hanya dari data pelatihan.\n",
    "\n",
    "Terapkan parameter yang sama tersebut ke data pelatihan dan juga data pengujian.\n",
    "\n",
    "Ini memastikan bahwa data pengujian tetap \"tidak terlihat\" oleh model selama proses pelatihan dan pra-pemrosesan.\n",
    "\n",
    "Gunakan Pipeline: Gunakan pipeline dari library seperti Scikit-learn. Pipeline akan mengotomatiskan proses ini, memastikan bahwa semua langkah pra-pemrosesan hanya dilakukan pada data pelatihan, dan kemudian diterapkan pada data pengujian. Ini adalah cara paling aman dan efisien untuk mencegah kebocoran.\n",
    "\n",
    "Hapus Fitur yang Mencurigakan: Jika ada fitur yang secara logis hanya bisa tersedia setelah peristiwa yang Anda prediksi terjadi, hapuslah fitur tersebut dari dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f254d9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9328644c",
   "metadata": {},
   "source": [
    "# 5. Data Understanding (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c309450",
   "metadata": {},
   "source": [
    "- Cari pattern yang berpengaruh pada model\n",
    "- Cari anomali yang mengurangi akurasi model\n",
    "- Dilakukan dengan EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff278bd3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c512ed9",
   "metadata": {},
   "source": [
    "# 6. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7cacef",
   "metadata": {},
   "source": [
    "- Handling Missing Values\n",
    "- Handling Kategorikal Variable\n",
    "- Scaling\n",
    "\n",
    "---\n",
    "1. Penanganan Nilai yang Hilang (Handling Missing Values) ğŸ—‘ï¸\n",
    "Nilai yang hilang (missing values) adalah celah atau data yang tidak tercatat dalam dataset. Menangani nilai ini sangat penting karena banyak model machine learning tidak bisa bekerja dengan data yang tidak lengkap.\n",
    "\n",
    "Cara mengatasinya:\n",
    "\n",
    "Menghapus (Deletion): Menghapus baris atau kolom yang memiliki nilai hilang. Metode ini sederhana, tetapi bisa menyebabkan hilangnya informasi penting.\n",
    "\n",
    "Imputasi (Imputation): Mengisi nilai yang hilang dengan nilai lain yang masuk akal. Ini adalah metode yang paling umum.\n",
    "\n",
    "Contoh Imputasi:\n",
    "Misalkan Anda memiliki kolom Usia dengan beberapa data yang hilang. Anda dapat mengisinya dengan:\n",
    "\n",
    "Nilai rata-rata (mean) dari semua usia yang ada. Ini efektif jika distribusinya normal.\n",
    "\n",
    "Nilai median (median) jika data memiliki pencilan (outliers).\n",
    "\n",
    "Nilai modus (mode) untuk data kategorikal.\n",
    "\n",
    "Menggunakan model machine learning lain untuk memprediksi nilai yang hilang.\n",
    "\n",
    "2. Penanganan Variabel Kategorikal (Handling Categorical Variables) ğŸ”¢\n",
    "Variabel kategorikal adalah fitur yang memiliki nilai dalam bentuk teks atau kategori, bukan angka. Contohnya seperti Warna (merah, biru, hijau) atau Jenis Kelamin (pria, wanita). Model machine learning hanya bisa memproses angka, jadi kita harus mengubah variabel ini menjadi format numerik.\n",
    "\n",
    "Cara mengatasinya:\n",
    "\n",
    "Label Encoding: Memberikan angka unik untuk setiap kategori.\n",
    "\n",
    "Contoh: merah -> 0, biru -> 1, hijau -> 2. Metode ini dapat menimbulkan masalah jika model salah menginterpretasikan angka tersebut sebagai urutan (ordinal).\n",
    "\n",
    "One-Hot Encoding: Membuat kolom biner baru (0 atau 1) untuk setiap kategori.\n",
    "\n",
    "Contoh: Untuk kolom Warna, dibuat tiga kolom baru: Warna_merah, Warna_biru, Warna_hijau. Jika baris data adalah \"merah\", maka Warna_merah = 1, sisanya 0. Ini lebih aman karena tidak ada asumsi urutan.\n",
    "\n",
    "3. Penskalaan (Scaling) âš–ï¸\n",
    "Penskalaan adalah proses mengubah nilai numerik dalam dataset ke dalam rentang atau skala yang sama. Ini penting karena beberapa algoritma machine learning sensitif terhadap skala fitur. Jika satu fitur memiliki nilai sangat besar dan fitur lain sangat kecil, model bisa menganggap fitur besar lebih penting.\n",
    "\n",
    "Cara mengatasinya:\n",
    "\n",
    "Standardisasi (Standard Scaling): Mengubah data sehingga memiliki rata-rata (mean) 0 dan standar deviasi 1. Cocok untuk data yang distribusinya mendekati normal.\n",
    "\n",
    "Rumus: X \n",
    "new\n",
    "â€‹\n",
    " =(Xâˆ’Î¼)/Ïƒ\n",
    "\n",
    "Normalisasi (Min-Max Scaling): Mengubah data ke dalam rentang 0 hingga 1. Cocok untuk data yang distribusinya tidak normal atau ketika Anda membutuhkan nilai dalam rentang tertentu.\n",
    "\n",
    "Rumus: X \n",
    "new\n",
    "â€‹\n",
    " =(Xâˆ’X \n",
    "min\n",
    "â€‹\n",
    " )/(X \n",
    "max\n",
    "â€‹\n",
    " âˆ’X \n",
    "min\n",
    "â€‹\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e07592",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 7. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ac7ee1",
   "metadata": {},
   "source": [
    "Rekayasa fitur (Feature Engineering) adalah proses menciptakan fitur (variabel) baru yang lebih bermakna dari data yang sudah ada. Tujuannya adalah untuk meningkatkan performa model machine learning. Rekayasa fitur sering disebut sebagai \"seni\" dalam data science karena membutuhkan kreativitas dan pengetahuan domain yang mendalam.\n",
    "\n",
    "Secara sederhana, proses ini mengubah data mentah menjadi representasi yang lebih baik, sehingga model dapat \"melihat\" pola yang lebih jelas. Semakin baik fiturnya, semakin baik pula kinerja model.\n",
    "\n",
    "Penggunaan Rekayasa Fitur ğŸ› ï¸\n",
    "Rekayasa fitur digunakan untuk berbagai tujuan, di antaranya:\n",
    "\n",
    "Meningkatkan Akurasi Model: Fitur yang lebih baik dapat membantu model membuat prediksi yang lebih akurat.\n",
    "\n",
    "Mengurangi Overfitting: Dengan menciptakan fitur yang lebih relevan dan tidak terlalu spesifik, kita bisa membantu model menggeneralisasi dengan lebih baik.\n",
    "\n",
    "Mempercepat Pelatihan Model: Fitur yang lebih ringkas dan informatif dapat membuat proses pelatihan menjadi lebih cepat.\n",
    "\n",
    "Mendapatkan Insight Baru: Proses ini seringkali mengungkap hubungan dan pola tersembunyi dalam data yang sebelumnya tidak terlihat.\n",
    "\n",
    "Macam-Macam Jenis Rekayasa Fitur\n",
    "Ada banyak teknik rekayasa fitur yang bisa diterapkan. Berikut adalah beberapa jenis yang paling umum:\n",
    "\n",
    "1. Imputasi (Imputation)\n",
    "Ini adalah teknik untuk mengisi nilai yang hilang dalam dataset. Meskipun sudah dijelaskan sebelumnya, imputasi juga merupakan bentuk rekayasa fitur karena mengubah data untuk menjadikannya lebih lengkap.\n",
    "\n",
    "Contoh: Mengganti nilai yang hilang di kolom Usia dengan rata-rata atau median dari kolom tersebut.\n",
    "\n",
    "2. Binning atau Discretization\n",
    "Teknik ini mengelompokkan nilai numerik ke dalam \"keranjang\" (bins) atau kategori.\n",
    "\n",
    "Contoh: Mengubah nilai Usia menjadi kategori Anak-anak (0-12), Remaja (13-19), Dewasa (20-60), dan Lanjut Usia (60+). Ini bisa membantu model jika hubungan antara usia dan target tidak linier.\n",
    "\n",
    "3. Log Transformation\n",
    "Ini adalah teknik mengubah fitur yang distribusinya miring (skewed) menjadi distribusi yang lebih normal. Ini sangat berguna untuk fitur yang memiliki rentang nilai yang sangat besar.\n",
    "\n",
    "Contoh: Menerapkan log() pada kolom Gaji untuk mengurangi dampak pencilan yang memiliki gaji sangat tinggi.\n",
    "\n",
    "4. Penggabungan Fitur (Feature Combination)\n",
    "Menciptakan fitur baru dengan menggabungkan dua atau lebih fitur yang sudah ada.\n",
    "\n",
    "Contoh: Menggabungkan kolom Panjang dan Lebar untuk membuat fitur baru bernama Luas. Dalam kasus lain, Anda bisa membuat Indeks Massa Tubuh (BMI) dari Berat dan Tinggi.\n",
    "\n",
    "5. Encoding\n",
    "Ini adalah proses mengubah variabel kategorikal menjadi format numerik. Meskipun sudah dibahas, ini adalah bagian integral dari rekayasa fitur.\n",
    "\n",
    "Contoh: Menggunakan One-Hot Encoding untuk mengubah kolom Kota menjadi beberapa kolom biner (Kota_Surabaya, Kota_Jakarta, dll.).\n",
    "\n",
    "6. Ekstraksi Fitur Berbasis Waktu\n",
    "Membuat fitur dari kolom tanggal dan waktu.\n",
    "\n",
    "Contoh: Mengekstrak Hari dalam seminggu, Bulan, atau Tahun dari kolom Tanggal. Fitur ini bisa sangat kuat karena banyak pola data yang bersifat musiman atau terkait waktu.\n",
    "\n",
    "7. Ekstraksi Fitur Berbasis Teks\n",
    "Mengubah data teks menjadi fitur numerik.\n",
    "\n",
    "Contoh: Menggunakan TF-IDF (Term Frequency-Inverse Document Frequency) atau Bag of Words untuk mengkonversi isi ulasan pelanggan menjadi vektor numerik yang bisa dipahami model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd71b8a2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 8. Model Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bba708",
   "metadata": {},
   "source": [
    "Apa itu Model Fitting? âš™ï¸\n",
    "\n",
    "Model fitting adalah proses di mana sebuah model machine learning \"belajar\" dari data pelatihan (training data). Tujuannya adalah agar model dapat menemukan pola dan hubungan di antara fitur (variabel) yang ada, sehingga dapat membuat prediksi yang akurat pada data baru.\n",
    "\n",
    "Bayangkan Anda sedang mengajari seorang anak untuk mengenali anjing. Anda menunjukkan banyak gambar anjing dengan berbagai ras dan ukuran. Proses ini adalah \"fitting\" model. Anak tersebut akan belajar ciri-ciri anjing (telinga, ekor, moncong, bulu) dan akhirnya bisa membedakan anjing dari hewan lain.\n",
    "\n",
    "Konsep-Konsep Utama dalam Model Fitting\n",
    "Ada tiga konsep utama yang sangat penting untuk dipahami dalam model fitting:\n",
    "\n",
    "1. Underfitting\n",
    "Underfitting terjadi ketika model terlalu sederhana dan tidak mampu menangkap pola dasar dari data. Akibatnya, model memiliki performa yang buruk pada data pelatihan maupun data pengujian.\n",
    "\n",
    "Penyebab:\n",
    "\n",
    "Menggunakan model yang terlalu sederhana (misalnya, regresi linier untuk data non-linier).\n",
    "\n",
    "Fitur yang tidak cukup.\n",
    "\n",
    "Gejala: Akurasi rendah pada data pelatihan dan pengujian.\n",
    "\n",
    "Solusi:\n",
    "\n",
    "Menggunakan model yang lebih kompleks.\n",
    "\n",
    "Menambah lebih banyak fitur (feature engineering).\n",
    "\n",
    "2. Overfitting\n",
    "Overfitting terjadi ketika model terlalu kompleks dan \"menghafal\" data pelatihan, termasuk noise atau anomali. Akibatnya, model bekerja sangat baik pada data pelatihan, tetapi performanya sangat buruk saat dihadapkan pada data pengujian atau data baru.\n",
    "\n",
    "Penyebab:\n",
    "\n",
    "Menggunakan model yang terlalu kompleks (misalnya, pohon keputusan yang terlalu dalam).\n",
    "\n",
    "Data pelatihan yang terlalu sedikit.\n",
    "\n",
    "Gejala: Akurasi tinggi pada data pelatihan, tetapi akurasi rendah pada data pengujian.\n",
    "\n",
    "Solusi:\n",
    "\n",
    "Menggunakan model yang lebih sederhana.\n",
    "\n",
    "Menambah lebih banyak data pelatihan.\n",
    "\n",
    "Menggunakan teknik regulasi (seperti L1 atau L2 regularization) untuk mengurangi kompleksitas model.\n",
    "\n",
    "Menggunakan cross-validation.\n",
    "\n",
    "3. Good Fit\n",
    "Good fit adalah kondisi ideal di mana model memiliki kompleksitas yang tepat. Model ini mampu menangkap pola utama dari data tanpa \"menghafal\" noise. Akibatnya, model berkinerja baik pada data pelatihan maupun data pengujian. Tujuan dari model fitting adalah untuk mencapai good fit ini.\n",
    "\n",
    "Proses Model Fitting dalam Praktik\n",
    "Pilih Model: Tentukan algoritma machine learning yang akan digunakan (misalnya, Linear Regression, Decision Tree, Support Vector Machine).\n",
    "\n",
    "Latih Model: Gunakan fungsi fit() pada data pelatihan. Selama proses ini, model menyesuaikan bobotnya agar dapat meminimalkan kesalahan prediksi.\n",
    "\n",
    "Evaluasi: Setelah model dilatih, gunakan data pengujian untuk mengevaluasi performanya. Langkah ini penting untuk melihat apakah model mengalami underfitting atau overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e42a860",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 9. Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7145b086",
   "metadata": {},
   "source": [
    "Eksperimen dengan Cross-Validation ğŸ”¬\n",
    "Cross-validation tidak hanya digunakan untuk mengevaluasi satu model, tetapi juga sebagai alat penting dalam serangkaian eksperimen untuk menemukan model terbaik. Dengan menggunakan cross-validation, kita bisa membandingkan hasil dari setiap eksperimen secara adil dan objektif. Berikut adalah contoh bagaimana cross-validation diterapkan dalam eksperimen:\n",
    "\n",
    "1. Variasi Hyperparameter\n",
    "Hyperparameter adalah parameter yang tidak dipelajari dari data, tetapi harus diatur sebelum pelatihan dimulai (misalnya, learning rate atau jumlah pohon dalam Random Forest).\n",
    "\n",
    "Tujuan Eksperimen: Menemukan nilai hyperparameter yang optimal untuk model Anda.\n",
    "\n",
    "Cara Kerja:\n",
    "\n",
    "Anda memiliki satu model (misalnya, Random Forest).\n",
    "\n",
    "Lakukan cross-validation (misalnya, 5-fold) untuk beberapa kombinasi hyperparameter yang berbeda.\n",
    "\n",
    "Misalnya, Anda menguji n_estimators = [10, 50, 100].\n",
    "\n",
    "Hitung rata-rata skor akurasi dari 5-fold cross-validation untuk setiap n_estimators tersebut.\n",
    "\n",
    "Hasil: Anda akan mendapatkan tiga skor rata-rata (misalnya, 82% untuk 10 pohon, 88% untuk 50 pohon, dan 87% untuk 100 pohon).\n",
    "\n",
    "Kesimpulan: Berdasarkan hasil ini, Anda dapat menyimpulkan bahwa 50 pohon adalah pilihan terbaik karena memberikan akurasi rata-rata tertinggi.\n",
    "\n",
    "2. Pra-pemrosesan Data (Variasi Scaling)\n",
    "Metode penskalaan (scaling) dapat memengaruhi performa beberapa model. Cross-validation membantu menentukan metode penskalaan mana yang paling cocok untuk model Anda.\n",
    "\n",
    "Tujuan Eksperimen: Membandingkan efektivitas Standard Scaling dan Min-Max Scaling.\n",
    "\n",
    "Cara Kerja:\n",
    "\n",
    "Eksperimen 1: Terapkan Standard Scaling pada data. Latih dan evaluasi model (misalnya, SVM) menggunakan cross-validation. Catat skor rata-ratanya (misalnya, 85%).\n",
    "\n",
    "Eksperimen 2: Terapkan Min-Max Scaling pada data yang sama. Latih dan evaluasi model yang sama menggunakan cross-validation. Catat skor rata-ratanya (misalnya, 82%).\n",
    "\n",
    "Kesimpulan: Berdasarkan perbandingan skor, Standard Scaling memberikan hasil yang lebih baik untuk model SVM ini.\n",
    "\n",
    "3. Rekayasa Fitur (Feature Engineering)\n",
    "Rekayasa fitur adalah proses menciptakan variabel baru dari data yang ada. Cross-validation sangat berguna untuk menguji apakah fitur baru yang Anda buat benar-benar meningkatkan performa model.\n",
    "\n",
    "Tujuan Eksperimen: Menilai apakah fitur baru (misalnya, BMI yang dibuat dari Berat dan Tinggi) bermanfaat.\n",
    "\n",
    "Cara Kerja:\n",
    "\n",
    "Eksperimen 1 (Baseline): Latih model dengan fitur asli tanpa BMI menggunakan cross-validation. Catat skor rata-ratanya (misalnya, 78%).\n",
    "\n",
    "Eksperimen 2: Tambahkan fitur BMI ke dalam dataset. Latih model yang sama dengan cross-validation. Catat skor rata-ratanya (misalnya, 81%).\n",
    "\n",
    "Kesimpulan: Karena skornya meningkat, Anda bisa menyimpulkan bahwa fitur BMI adalah fitur yang berguna dan dapat dipertahankan.\n",
    "\n",
    "Dengan menggunakan cross-validation dalam setiap langkah eksperimen, Anda memastikan bahwa keputusan yang Anda ambil tentang model, hyperparameter, dan fitur didasarkan pada evaluasi yang solid dan tidak rentan terhadap kebetulan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76672eb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 10. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eedbdc",
   "metadata": {},
   "source": [
    "Metode Evaluasi (Evaluation Methods) ğŸ“Š\n",
    "Metode evaluasi adalah serangkaian teknik dan metrik untuk mengukur kinerja model machine learning. Tujuannya adalah untuk menilai seberapa baik model dapat membuat prediksi yang akurat dan dapat diandalkan, serta untuk membandingkan model-model yang berbeda. Ada dua kategori utama, yaitu untuk masalah klasifikasi dan regresi.\n",
    "\n",
    "1. Masalah Klasifikasi (Classification)\n",
    "Pada masalah klasifikasi, model memprediksi kategori atau kelas (misalnya, \"spam\" atau \"bukan spam\").\n",
    "\n",
    "Matriks Kebingungan (Confusion Matrix): Ini adalah dasar dari sebagian besar metrik klasifikasi. Matriks ini menampilkan empat hasil prediksi: True Positive (TP), True Negative (TN), False Positive (FP), dan False Negative (FN).\n",
    "\n",
    "Akurasi (Accuracy): Mengukur proporsi total prediksi yang benar. Metrik ini berguna untuk dataset yang seimbang, tetapi bisa menyesatkan pada dataset yang tidak seimbang.\n",
    "\n",
    "Rumus: (TP+TN)/(TP+TN+FP+FN)\n",
    "\n",
    "Presisi (Precision): Mengukur seberapa banyak prediksi positif yang benar. Penting ketika biaya False Positive tinggi.\n",
    "\n",
    "Rumus: TP/(TP+FP)\n",
    "\n",
    "Rekal (Recall) / Sensitivitas: Mengukur seberapa banyak kasus positif yang berhasil ditemukan. Penting ketika biaya False Negative tinggi.\n",
    "\n",
    "Rumus: TP/(TP+FN)\n",
    "\n",
    "Skor F1 (F1-Score): Nilai rata-rata harmonik dari Presisi dan Rekal. Berguna untuk mencari keseimbangan antara kedua metrik, terutama pada dataset yang tidak seimbang.\n",
    "\n",
    "Rumus: 2âˆ—(Presisiâˆ—Rekal)/(Presisi+Rekal)\n",
    "\n",
    "Kurva ROC-AUC: Mengukur kemampuan model untuk membedakan antara kelas positif dan negatif. Nilai AUC (Area Under the Curve) yang mendekati 1 menunjukkan kinerja yang sangat baik, sementara nilai 0.5 menunjukkan kinerja acak. Metrik ini sangat baik untuk dataset yang tidak seimbang.\n",
    "\n",
    "2. Masalah Regresi (Regression)\n",
    "Pada masalah regresi, model memprediksi nilai numerik kontinu (misalnya, harga rumah).\n",
    "\n",
    "Kesalahan Mutlak Rata-Rata (Mean Absolute Error / MAE): Mengukur rata-rata selisih mutlak antara nilai prediksi dan nilai sebenarnya.\n",
    "\n",
    "Rumus:  \n",
    "n\n",
    "1\n",
    "â€‹\n",
    " âˆ‘ \n",
    "i=1\n",
    "n\n",
    "â€‹\n",
    " âˆ£y \n",
    "i\n",
    "â€‹\n",
    " âˆ’ \n",
    "y\n",
    "^\n",
    "â€‹\n",
    "  \n",
    "i\n",
    "â€‹\n",
    " âˆ£\n",
    "\n",
    "Kesalahan Kuadrat Rata-Rata (Mean Squared Error / MSE): Mengukur rata-rata kuadrat selisih antara nilai prediksi dan nilai sebenarnya. MSE memberikan bobot yang lebih besar pada kesalahan yang besar.\n",
    "\n",
    "Rumus:  \n",
    "n\n",
    "1\n",
    "â€‹\n",
    " âˆ‘ \n",
    "i=1\n",
    "n\n",
    "â€‹\n",
    " (y \n",
    "i\n",
    "â€‹\n",
    " âˆ’ \n",
    "y\n",
    "^\n",
    "â€‹\n",
    "  \n",
    "i\n",
    "â€‹\n",
    " ) \n",
    "2\n",
    " \n",
    "\n",
    "Akar Kesalahan Kuadrat Rata-Rata (Root Mean Squared Error / RMSE): Akar kuadrat dari MSE. Metrik ini lebih mudah diinterpretasikan karena memiliki satuan yang sama dengan variabel target.\n",
    "\n",
    "Rumus:  \n",
    "n\n",
    "1\n",
    "â€‹\n",
    " âˆ‘ \n",
    "i=1\n",
    "n\n",
    "â€‹\n",
    " (y \n",
    "i\n",
    "â€‹\n",
    " âˆ’ \n",
    "y\n",
    "^\n",
    "â€‹\n",
    "  \n",
    "i\n",
    "â€‹\n",
    " ) \n",
    "2\n",
    " \n",
    "\n",
    "â€‹\n",
    " \n",
    "\n",
    "R-Squared (R \n",
    "2\n",
    " ): Mengukur proporsi varians dalam variabel target yang dapat dijelaskan oleh model. Nilai R \n",
    "2\n",
    "  berkisar dari 0 hingga 1. Semakin dekat ke 1, semakin baik modelnya.\n",
    "\n",
    "Baseline dan Pentingnya ğŸ¯\n",
    "Baseline adalah model sederhana yang digunakan sebagai titik acuan untuk membandingkan kinerja model machine learning Anda yang lebih kompleks. Baseline membantu Anda menentukan apakah model Anda benar-benar efektif atau hanya lebih baik dari tebakan acak.\n",
    "\n",
    "Jenis-Jenis Baseline:\n",
    "\n",
    "Baseline Acak (Random Baseline): Memprediksi secara acak. Misalnya, untuk klasifikasi biner, model ini memprediksi 50% \"ya\" dan 50% \"tidak\".\n",
    "\n",
    "Baseline Mayoritas Kelas (Majority Class Baseline): Memprediksi kelas yang paling sering muncul dalam dataset.\n",
    "\n",
    "Contoh: Jika 95% email adalah \"bukan spam,\" baseline ini selalu memprediksi \"bukan spam.\" Akurasi baseline ini adalah 95%, dan model Anda harus bisa mengalahkan angka ini untuk dianggap berguna.\n",
    "\n",
    "Baseline Statistik: Menggunakan statistik sederhana.\n",
    "\n",
    "Contoh (Regresi): Menggunakan rata-rata (mean) atau median dari data target sebagai prediksi untuk semua data. Jika model regresi Anda tidak bisa mengalahkan prediksi rata-rata ini, maka model tersebut tidak efektif."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef07787",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 11. Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa988421",
   "metadata": {},
   "source": [
    "- Kita ingin tau sumber eror dari model\n",
    "- sehingga dapat meningkatkan performa model\n",
    "- Dilakukan dengan memeriksa kesalahan yang terjadi pada test set, dan memahami mengapa hal tersebut salah"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
